"""
Agentic Telemetry Service - Observability and Monitoring

Telemetry service for tracking agent execution, tool usage, and performance metrics.

WHAT (Telemetry Role): I track agent execution, tool usage, and performance
HOW (Telemetry Implementation): I record telemetry data to Supabase and provide metrics

Key Principle: All agent operations should be observable for debugging, optimization, and cost tracking.
"""

import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).resolve().parents[5]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from utilities import get_logger, get_clock
from symphainy_platform.runtime.execution_context import ExecutionContext


class AgenticTelemetryService:
    """
    Agentic Telemetry Service - Observability and monitoring for agents.
    
    Provides:
    - Agent execution tracking (prompts, responses, tokens, costs)
    - Tool usage tracking (which tools, how often, success/failure)
    - Performance metrics (latency, throughput, error rates)
    - Health monitoring (agent availability, resource usage)
    - Cost tracking (LLM costs per agent, per tenant)
    """
    
    def __init__(self, supabase_adapter: Optional[Any] = None):
        """
        Initialize Agentic Telemetry Service.
        
        Args:
            supabase_adapter: Supabase adapter for storage
        """
        self.logger = get_logger(self.__class__.__name__)
        self.clock = get_clock()
        self.supabase_adapter = supabase_adapter
    
    async def record_agent_execution(
        self,
        agent_id: str,
        agent_name: str,
        prompt: str,
        response: str,
        model_name: str,
        tokens: Dict[str, int],
        cost: float,
        latency_ms: float,
        context: ExecutionContext,
        success: bool = True,
        error_message: Optional[str] = None
    ) -> bool:
        """
        Record agent execution for telemetry.
        
        Args:
            agent_id: Agent identifier
            agent_name: Agent name
            prompt: Prompt sent to LLM
            response: Response from LLM
            model_name: Model name (e.g., "gpt-4o-mini")
            tokens: Token usage (prompt_tokens, completion_tokens, total_tokens)
            cost: Cost in USD
            latency_ms: Latency in milliseconds
            context: Execution context
            success: Whether execution succeeded
            error_message: Optional error message
        
        Returns:
            True if recording successful
        """
        if not self.supabase_adapter:
            self.logger.debug("Supabase adapter not available, skipping telemetry recording")
            return False
        
        try:
            # Calculate prompt hash for deduplication
            import hashlib
            prompt_hash = hashlib.sha256(prompt.encode()).hexdigest()[:16]
            
            # Prepare execution log record
            execution_record = {
                "id": None,  # Will be generated by database
                "agent_id": agent_id,
                "agent_name": agent_name,
                "tenant_id": context.tenant_id,
                "session_id": context.session_id,
                "execution_id": context.execution_id,
                "prompt_hash": prompt_hash,
                "prompt_tokens": tokens.get("prompt_tokens", 0),
                "completion_tokens": tokens.get("completion_tokens", 0),
                "total_tokens": tokens.get("total_tokens", 0),
                "cost": cost,
                "latency_ms": int(latency_ms),
                "model_name": model_name,
                "success": success,
                "error_message": error_message,
                "created_at": self.clock.now().isoformat() if self.clock else datetime.utcnow().isoformat()
            }
            
            # Insert into Supabase
            result = await self.supabase_adapter.execute_rls_policy(
                table="agentic_execution_log",
                operation="insert",
                user_context={"tenant_id": context.tenant_id},
                data=execution_record
            )
            
            if result.get("success"):
                self.logger.debug(f"✅ Recorded agent execution: {agent_id}")
                return True
            else:
                self.logger.warning(f"Failed to record agent execution: {result.get('error')}")
                return False
                
        except Exception as e:
            self.logger.error(f"Exception recording agent execution: {e}", exc_info=True)
            return False
    
    async def record_agent_tool_usage(
        self,
        agent_id: str,
        tool_name: str,
        parameters: Dict[str, Any],
        result: Dict[str, Any],
        context: ExecutionContext,
        latency_ms: Optional[float] = None
    ) -> bool:
        """
        Record tool usage for telemetry.
        
        Args:
            agent_id: Agent identifier
            tool_name: Tool name
            parameters: Tool parameters
            result: Tool result
            context: Execution context
            latency_ms: Optional latency in milliseconds
        
        Returns:
            True if recording successful
        """
        if not self.supabase_adapter:
            self.logger.debug("Supabase adapter not available, skipping tool usage recording")
            return False
        
        try:
            # Extract server name from tool name if available
            server_name = None
            if "_" in tool_name:
                parts = tool_name.split("_", 1)
                if len(parts) == 2:
                    server_name = f"{parts[0]}_mcp"
            
            # Determine success from result
            success = result.get("success", True) if isinstance(result, dict) else True
            
            # Prepare tool usage log record
            tool_record = {
                "id": None,  # Will be generated by database
                "agent_id": agent_id,
                "tool_name": tool_name,
                "server_name": server_name,
                "parameters": parameters,
                "result": result,
                "success": success,
                "latency_ms": int(latency_ms) if latency_ms else None,
                "tenant_id": context.tenant_id,
                "session_id": context.session_id,
                "created_at": self.clock.now().isoformat() if self.clock else datetime.utcnow().isoformat()
            }
            
            # Insert into Supabase
            result_db = await self.supabase_adapter.execute_rls_policy(
                table="agentic_tool_usage_log",
                operation="insert",
                user_context={"tenant_id": context.tenant_id},
                data=tool_record
            )
            
            if result_db.get("success"):
                self.logger.debug(f"✅ Recorded tool usage: {agent_id} -> {tool_name}")
                return True
            else:
                self.logger.warning(f"Failed to record tool usage: {result_db.get('error')}")
                return False
                
        except Exception as e:
            self.logger.error(f"Exception recording tool usage: {e}", exc_info=True)
            return False
    
    async def record_agent_health(
        self,
        agent_id: str,
        agent_name: str,
        health_status: Dict[str, Any],
        tenant_id: Optional[str] = None
    ) -> bool:
        """
        Record agent health metrics.
        
        Args:
            agent_id: Agent identifier
            agent_name: Agent name
            health_status: Health status dictionary
            tenant_id: Optional tenant identifier
        
        Returns:
            True if recording successful
        """
        if not self.supabase_adapter:
            self.logger.debug("Supabase adapter not available, skipping health recording")
            return False
        
        try:
            # Prepare health metrics record
            health_record = {
                "id": None,  # Will be generated by database
                "agent_id": agent_id,
                "agent_name": agent_name,
                "health_status": health_status,
                "tenant_id": tenant_id or "platform",
                "created_at": self.clock.now().isoformat() if self.clock else datetime.utcnow().isoformat()
            }
            
            # Insert into Supabase
            result = await self.supabase_adapter.execute_rls_policy(
                table="agentic_health_metrics",
                operation="insert",
                user_context={"tenant_id": tenant_id or "platform"},
                data=health_record
            )
            
            if result.get("success"):
                self.logger.debug(f"✅ Recorded agent health: {agent_id}")
                return True
            else:
                self.logger.warning(f"Failed to record agent health: {result.get('error')}")
                return False
                
        except Exception as e:
            self.logger.error(f"Exception recording agent health: {e}", exc_info=True)
            return False
    
    async def get_agent_metrics(
        self,
        agent_id: str,
        tenant_id: Optional[str] = None,
        time_range: Optional[Tuple[datetime, datetime]] = None
    ) -> Dict[str, Any]:
        """
        Get agent metrics for time range.
        
        Args:
            agent_id: Agent identifier
            tenant_id: Optional tenant identifier
            time_range: Optional time range (start, end)
        
        Returns:
            Dict with metrics:
            {
                "execution_count": int,
                "total_tokens": int,
                "total_cost": float,
                "avg_latency_ms": float,
                "success_rate": float,
                "tool_usage": Dict[str, int],
                "error_rate": float
            }
        """
        if not self.supabase_adapter:
            self.logger.warning("Supabase adapter not available, cannot retrieve metrics")
            return {}
        
        try:
            # Build filters
            filters = {"agent_id": agent_id}
            if tenant_id:
                filters["tenant_id"] = tenant_id
            
            if time_range:
                start_time, end_time = time_range
                filters["created_at__gte"] = start_time.isoformat()
                filters["created_at__lte"] = end_time.isoformat()
            
            # Query execution logs
            result = await self.supabase_adapter.execute_rls_policy(
                table="agentic_execution_log",
                operation="select",
                user_context={"tenant_id": tenant_id or "platform"},
                filters=filters
            )
            
            if not result.get("success") or not result.get("data"):
                # Return empty metrics structure
                return {
                    "execution_count": 0,
                    "total_tokens": 0,
                    "total_cost": 0.0,
                    "avg_latency_ms": 0.0,
                    "success_rate": 0.0,
                    "tool_usage": {},
                    "error_rate": 0.0
                }
            
            records = result["data"]
            
            # Calculate metrics
            execution_count = len(records)
            total_tokens = sum(r.get("total_tokens", 0) for r in records)
            total_cost = sum(float(r.get("cost", 0)) for r in records)
            latencies = [r.get("latency_ms", 0) for r in records if r.get("latency_ms")]
            avg_latency_ms = sum(latencies) / len(latencies) if latencies else 0.0
            success_count = sum(1 for r in records if r.get("success", True))
            success_rate = success_count / execution_count if execution_count > 0 else 0.0
            error_rate = 1.0 - success_rate
            
            # Get tool usage
            tool_result = await self.supabase_adapter.execute_rls_policy(
                table="agentic_tool_usage_log",
                operation="select",
                user_context={"tenant_id": tenant_id or "platform"},
                filters={"agent_id": agent_id}
            )
            
            tool_usage = {}
            if tool_result.get("success") and tool_result.get("data"):
                tool_records = tool_result["data"]
                for record in tool_records:
                    tool_name = record.get("tool_name", "unknown")
                    tool_usage[tool_name] = tool_usage.get(tool_name, 0) + 1
            
            return {
                "execution_count": execution_count,
                "total_tokens": total_tokens,
                "total_cost": total_cost,
                "avg_latency_ms": avg_latency_ms,
                "success_rate": success_rate,
                "tool_usage": tool_usage,
                "error_rate": error_rate
            }
            
        except Exception as e:
            self.logger.error(f"Exception retrieving agent metrics: {e}", exc_info=True)
            return {}
    
    async def record_orchestrator_execution(
        self,
        orchestrator_id: str,
        orchestrator_name: str,
        intent_type: str,
        latency_ms: float,
        context: ExecutionContext,
        success: bool = True,
        error_message: Optional[str] = None
    ) -> bool:
        """
        Record orchestrator execution for telemetry.
        
        Args:
            orchestrator_id: Orchestrator identifier
            orchestrator_name: Orchestrator name
            intent_type: Intent type handled
            latency_ms: Latency in milliseconds
            context: Execution context
            success: Whether execution succeeded
            error_message: Optional error message
        
        Returns:
            True if recording successful
        """
        if not self.supabase_adapter:
            self.logger.debug("Supabase adapter not available, skipping orchestrator telemetry")
            return False
        
        try:
            execution_record = {
                "id": None,
                "orchestrator_id": orchestrator_id,
                "orchestrator_name": orchestrator_name,
                "tenant_id": context.tenant_id,
                "session_id": context.session_id,
                "execution_id": context.execution_id,
                "intent_type": intent_type,
                "latency_ms": latency_ms,
                "success": success,
                "error_message": error_message,
                "created_at": self.clock.now().isoformat() if self.clock else datetime.utcnow().isoformat()
            }
            
            result = await self.supabase_adapter.execute_rls_policy(
                table="orchestrator_execution_log",
                operation="insert",
                user_context={"tenant_id": context.tenant_id},
                data=execution_record
            )
            
            if result.get("success"):
                self.logger.debug(f"✅ Recorded orchestrator execution: {orchestrator_id}/{intent_type}")
                return True
            else:
                self.logger.warning(f"Failed to record orchestrator execution: {result.get('error')}")
                return False
                
        except Exception as e:
            self.logger.error(f"Exception recording orchestrator execution: {e}", exc_info=True)
            return False
    
    async def record_orchestrator_health(
        self,
        orchestrator_id: str,
        orchestrator_name: str,
        health_status: Dict[str, Any],
        tenant_id: Optional[str] = None
    ) -> bool:
        """
        Record orchestrator health metrics.
        
        Args:
            orchestrator_id: Orchestrator identifier
            orchestrator_name: Orchestrator name
            health_status: Health status dictionary
            tenant_id: Optional tenant identifier
        
        Returns:
            True if recording successful
        """
        if not self.supabase_adapter:
            self.logger.debug("Supabase adapter not available, skipping health recording")
            return False
        
        try:
            health_record = {
                "id": None,
                "orchestrator_id": orchestrator_id,
                "orchestrator_name": orchestrator_name,
                "health_status": health_status,
                "tenant_id": tenant_id or "platform",
                "created_at": self.clock.now().isoformat() if self.clock else datetime.utcnow().isoformat()
            }
            
            result = await self.supabase_adapter.execute_rls_policy(
                table="orchestrator_health_metrics",
                operation="insert",
                user_context={"tenant_id": tenant_id or "platform"},
                data=health_record
            )
            
            if result.get("success"):
                self.logger.debug(f"✅ Recorded orchestrator health: {orchestrator_id}")
                return True
            else:
                self.logger.warning(f"Failed to record orchestrator health: {result.get('error')}")
                return False
                
        except Exception as e:
            self.logger.error(f"Exception recording orchestrator health: {e}", exc_info=True)
            return False
    
    async def get_orchestrator_metrics(
        self,
        orchestrator_id: str,
        tenant_id: Optional[str] = None,
        time_range: Optional[Tuple[datetime, datetime]] = None
    ) -> Dict[str, Any]:
        """
        Get orchestrator metrics for time range.
        
        Args:
            orchestrator_id: Orchestrator identifier
            tenant_id: Optional tenant identifier
            time_range: Optional time range (start, end)
        
        Returns:
            Dict with metrics:
            {
                "intent_count": int,
                "avg_latency_ms": float,
                "success_rate": float,
                "error_rate": float,
                "intent_types": Dict[str, int]
            }
        """
        if not self.supabase_adapter:
            self.logger.warning("Supabase adapter not available, cannot retrieve metrics")
            return {}
        
        try:
            filters = {"orchestrator_id": orchestrator_id}
            if tenant_id:
                filters["tenant_id"] = tenant_id
            
            if time_range:
                start_time, end_time = time_range
                filters["created_at__gte"] = start_time.isoformat()
                filters["created_at__lte"] = end_time.isoformat()
            
            result = await self.supabase_adapter.execute_rls_policy(
                table="orchestrator_execution_log",
                operation="select",
                user_context={"tenant_id": tenant_id or "platform"},
                filters=filters
            )
            
            if not result.get("success") or not result.get("data"):
                return {
                    "intent_count": 0,
                    "avg_latency_ms": 0.0,
                    "success_rate": 0.0,
                    "error_rate": 0.0,
                    "intent_types": {}
                }
            
            records = result["data"]
            
            intent_count = len(records)
            latencies = [r.get("latency_ms", 0) for r in records if r.get("latency_ms")]
            avg_latency_ms = sum(latencies) / len(latencies) if latencies else 0.0
            success_count = sum(1 for r in records if r.get("success", True))
            success_rate = success_count / intent_count if intent_count > 0 else 0.0
            error_rate = 1.0 - success_rate
            
            # Count intent types
            intent_types = {}
            for record in records:
                intent_type = record.get("intent_type", "unknown")
                intent_types[intent_type] = intent_types.get(intent_type, 0) + 1
            
            return {
                "intent_count": intent_count,
                "avg_latency_ms": avg_latency_ms,
                "success_rate": success_rate,
                "error_rate": error_rate,
                "intent_types": intent_types
            }
            
        except Exception as e:
            self.logger.error(f"Exception retrieving orchestrator metrics: {e}", exc_info=True)
            return {}
