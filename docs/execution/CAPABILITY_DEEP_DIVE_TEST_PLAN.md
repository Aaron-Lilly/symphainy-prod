# Capability Deep Dive Test Plan

**Date:** January 18, 2026  
**Purpose:** Systematic testing of ALL platform capabilities to ensure they ACTUALLY WORK  
**Status:** ðŸ”´ CRITICAL - Required before executive demo

---

## Core Principles

**âš ï¸ ABSOLUTE REQUIREMENTS:**
1. **NO MOCKS** - Test against real services, real databases, real storage
2. **NO FALLBACKS** - If something fails, fix it, don't work around it
3. **NO HARD-CODED CHEATS** - No fake data, no shortcuts, no "test mode" bypasses
4. **EXECUTION COMPLETION DEPTH** - Don't just test intent submission, test full execution
5. **ARTIFACT VALIDATION** - Verify artifacts are actually created and meaningful
6. **REAL FUNCTIONALITY** - Agents must reason, orchestrators must orchestrate, artifacts must be meaningful

---

## Test Pattern (MANDATORY)

Every capability test MUST follow this pattern:

```python
async def test_[capability]_[intent_type]_completion():
    """
    Test that [capability] intent actually completes and produces valid artifacts.
    
    NO MOCKS, NO FALLBACKS, NO CHEATS.
    """
    # 1. Get valid authentication token
    token = await get_valid_token()
    
    # 2. Submit intent with real parameters
    result = await submit_intent(
        token=token,
        intent_type="[intent_type]",
        parameters={...}  # Real parameters, not mocks
    )
    assert result is not None
    execution_id = result.get("execution_id")
    assert execution_id is not None
    
    # 3. Poll execution status until completion (REAL execution, not mocked)
    status = await poll_execution_status(execution_id, timeout=60)
    assert status is not None
    assert status.get("status") == "completed", f"Execution failed: {status.get('error')}"
    
    # 4. Validate artifacts exist (REAL artifacts, not placeholders)
    artifacts = status.get("artifacts", {})
    assert "[expected_artifact_key]" in artifacts
    
    # 5. Validate artifact quality (REAL validation, not just "exists")
    artifact = artifacts["[expected_artifact_key]"]
    assert artifact is not None
    assert len(artifact) > 0  # Not empty
    
    # 6. Validate artifact is retrievable (REAL retrieval from storage)
    artifact_id = artifacts.get("[artifact_key]_id")
    if artifact_id:
        retrieved = await get_artifact_by_id(artifact_id, "test_tenant", token=token)
        assert retrieved is not None
        assert retrieved == artifact or retrieved.get("artifact_id") == artifact_id
    
    # 7. Validate visual artifacts (if applicable) - REAL image validation
    if "[visual_key]" in artifacts:
        visual = artifacts["[visual_key]"]
        if "image_base64" in visual:
            assert validate_image_base64(visual["image_base64"])
        if "storage_path" in visual:
            visual_bytes = await get_visual_by_path(visual["storage_path"], "test_tenant", token=token)
            assert visual_bytes is not None
            assert len(visual_bytes) > 0
    
    # 8. Validate artifact meaning (REAL content validation)
    # Artifact must contain expected data structure, not just be a placeholder
    # Example: workflow artifact must contain workflow data, not just {"status": "created"}
```

---

## Capability Test Matrix

### Content Realm Capabilities

#### 1. File Management
**Intents:** `register_file`, `retrieve_file`, `list_files`, `get_file_by_id`

**Deep Dive Tests Required:**
- âœ… File registration completes and file is stored
- âœ… File metadata is created in Supabase
- âœ… File is retrievable by file_id
- âœ… File listing returns actual files
- âœ… No mock data or placeholder responses

**Test File:** `tests/integration/capabilities/test_file_management_capability.py`

---

#### 2. Data Ingestion
**Intents:** `ingest_file` (upload, EDI, API)

**Deep Dive Tests Required:**
- âœ… Upload ingestion completes and file is stored
- âœ… EDI ingestion processes EDI format correctly
- âœ… API ingestion accepts data via API
- âœ… Ingested files are parseable
- âœ… Ingestion metadata is tracked

**Test File:** `tests/integration/capabilities/test_data_ingestion_capability.py`

---

#### 3. File Parsing
**Intents:** `parse_content` (PDF, Excel, CSV, JSON, HTML, Word, Mainframe, Images)

**Deep Dive Tests Required:**
- âœ… PDF parsing extracts actual text/content
- âœ… Excel parsing extracts actual data/worksheets
- âœ… CSV parsing extracts actual rows/columns
- âœ… JSON parsing extracts actual structure
- âœ… HTML parsing extracts actual content
- âœ… Word parsing extracts actual text
- âœ… Mainframe parsing extracts actual data
- âœ… Image parsing extracts actual metadata
- âœ… Parsed results are stored and retrievable
- âœ… Parsed results contain meaningful data (not empty/placeholder)

**Test File:** `tests/integration/capabilities/test_file_parsing_capability.py`

---

#### 4. Bulk Operations
**Intents:** `bulk_ingest_files`, `bulk_parse_files`, `get_operation_status`

**Deep Dive Tests Required:**
- âœ… Bulk ingestion processes multiple files
- âœ… Bulk parsing processes multiple files
- âœ… Bulk operations track status correctly
- âœ… Operation status API returns real status
- âœ… All files in bulk operation are processed
- âœ… Results are stored for each file

**Test File:** `tests/integration/capabilities/test_bulk_operations_capability.py`

---

#### 5. File Lifecycle
**Intents:** `archive_file`, `restore_file`, `purge_file`, `validate_file`, `search_files`

**Deep Dive Tests Required:**
- âœ… File archiving moves file to archive state
- âœ… Archived files are not in active listings
- âœ… File restoration returns file to active state
- âœ… File purging removes file permanently
- âœ… File validation checks file integrity
- âœ… File search returns relevant results

**Test File:** `tests/integration/capabilities/test_file_lifecycle_capability.py`

---

### Insights Realm Capabilities

#### 6. Data Quality Assessment
**Intent:** `assess_data_quality`

**Deep Dive Tests Required:**
- âœ… Assessment completes and returns quality metrics
- âœ… Metrics are meaningful (not just "quality: good")
- âœ… Assessment identifies actual issues
- âœ… Results are stored as artifacts
- âœ… Results are retrievable

**Test File:** `tests/integration/capabilities/test_data_quality_capability.py`

---

#### 7. Semantic Interpretation
**Intents:** `interpret_data_self_discovery`, `interpret_data_guided`

**Deep Dive Tests Required:**
- âœ… Interpretation completes and extracts meaning
- âœ… Semantic relationships are identified
- âœ… Results contain actual semantic data (not placeholders)
- âœ… Results are stored and retrievable

**Test File:** `tests/integration/capabilities/test_semantic_interpretation_capability.py`

---

#### 8. Interactive Analysis
**Intents:** `analyze_structured_data`, `analyze_unstructured_data`

**Deep Dive Tests Required:**
- âœ… Analysis completes and produces insights
- âœ… Insights are meaningful (not generic responses)
- âœ… Analysis handles structured data correctly
- âœ… Analysis handles unstructured data correctly
- âœ… Results are stored and retrievable

**Test File:** `tests/integration/capabilities/test_interactive_analysis_capability.py`

---

#### 9. Guided Discovery
**Intent:** `interpret_data_guided`

**Deep Dive Tests Required:**
- âœ… Discovery completes and produces findings
- âœ… Findings are relevant to data
- âœ… Discovery follows guided process
- âœ… Results are stored and retrievable

**Test File:** `tests/integration/capabilities/test_guided_discovery_capability.py`

---

#### 10. Lineage Tracking
**Intent:** `visualize_lineage`

**Deep Dive Tests Required:**
- âœ… Lineage visualization completes
- âœ… Lineage data is accurate (tracks actual transformations)
- âœ… Visual is generated (if applicable)
- âœ… Lineage graph is meaningful (not empty)
- âœ… Results are stored and retrievable

**Test File:** `tests/integration/capabilities/test_lineage_tracking_capability.py`

---

### Journey Realm Capabilities

#### 11. Workflow Creation
**Intent:** `create_workflow`

**Deep Dive Tests Required:**
- âœ… Workflow creation completes successfully
- âœ… Workflow artifact is created and stored
- âœ… Workflow contains actual workflow data (not placeholder)
- âœ… Workflow visual is generated (if applicable)
- âœ… Visual is valid image (if applicable)
- âœ… Workflow is retrievable by artifact_id
- âœ… Workflow can be used by other capabilities

**Test File:** `tests/integration/capabilities/test_workflow_creation_capability.py`

---

#### 12. SOP Generation
**Intents:** `generate_sop`, `generate_sop_from_chat`, `sop_chat_message`

**Deep Dive Tests Required:**
- âœ… SOP generation completes successfully
- âœ… SOP artifact is created and stored
- âœ… SOP contains actual SOP content (not placeholder)
- âœ… SOP visual is generated (if applicable)
- âœ… Visual is valid image (if applicable)
- âœ… SOP is retrievable by artifact_id
- âœ… Chat-based SOP generation works end-to-end
- âœ… Multi-turn SOP chat preserves context

**Test File:** `tests/integration/capabilities/test_sop_generation_capability.py`

---

#### 13. Visual Generation
**Intent:** (Embedded in workflow/SOP creation)

**Deep Dive Tests Required:**
- âœ… Visuals are actually generated (not just "visual_path" placeholder)
- âœ… Visual images are valid (can be decoded, displayed)
- âœ… Visuals are stored in GCS
- âœ… Visuals are retrievable by path
- âœ… Visuals match artifact content (workflow visual matches workflow)
- âœ… Visual generation failures are reported (not silently ignored)

**Test File:** `tests/integration/capabilities/test_visual_generation_capability.py`

---

#### 14. Coexistence Analysis
**Intent:** `analyze_coexistence`

**Deep Dive Tests Required:**
- âœ… Analysis completes successfully
- âœ… Analysis identifies actual process interactions
- âœ… Results contain meaningful coexistence data
- âœ… Results are stored and retrievable

**Test File:** `tests/integration/capabilities/test_coexistence_analysis_capability.py`

---

#### 15. Coexistence Blueprint
**Intent:** `create_blueprint`

**Deep Dive Tests Required:**
- âœ… Blueprint creation completes successfully
- âœ… Blueprint artifact is created and stored
- âœ… Blueprint contains actual blueprint data (workflow charts, responsibility matrix)
- âœ… Blueprint visual is generated (if applicable)
- âœ… Visual is valid image (if applicable)
- âœ… Blueprint is retrievable by artifact_id

**Test File:** `tests/integration/capabilities/test_coexistence_blueprint_capability.py`

---

### Outcomes Realm Capabilities

#### 16. Solution Synthesis
**Intent:** `synthesize_outcome`

**Deep Dive Tests Required:**
- âœ… Synthesis completes successfully
- âœ… Solution artifact is created and stored
- âœ… Solution contains actual solution data (not placeholder)
- âœ… Solution visual is generated (if applicable)
- âœ… Visual is valid image (if applicable)
- âœ… Solution is retrievable by artifact_id
- âœ… Solution synthesizes from multiple insights (not just one source)

**Test File:** `tests/integration/capabilities/test_solution_synthesis_capability.py`

---

#### 17. Roadmap Generation
**Intent:** `generate_roadmap`

**Deep Dive Tests Required:**
- âœ… Roadmap generation completes successfully
- âœ… Roadmap artifact is created and stored
- âœ… Roadmap contains actual roadmap data (phases, milestones, timelines)
- âœ… Roadmap visual is generated (if applicable)
- âœ… Visual is valid image (if applicable)
- âœ… Roadmap is retrievable by artifact_id
- âœ… Roadmap is based on actual Content/Insights/Journey outputs

**Test File:** `tests/integration/capabilities/test_roadmap_generation_capability.py`

---

#### 18. POC Creation
**Intent:** `create_poc`

**Deep Dive Tests Required:**
- âœ… POC creation completes successfully
- âœ… POC artifact is created and stored
- âœ… POC contains actual POC data (not placeholder)
- âœ… POC visual is generated (if applicable)
- âœ… Visual is valid image (if applicable)
- âœ… POC is retrievable by artifact_id

**Test File:** `tests/integration/capabilities/test_poc_creation_capability.py`

---

### Admin Dashboard Capabilities

#### 19. Control Room
**Intents:** (Service endpoints for observability)

**Deep Dive Tests Required:**
- âœ… Control Room endpoints return real platform metrics
- âœ… Metrics are accurate (not hard-coded)
- âœ… Service health reflects actual service state
- âœ… Execution statistics reflect actual executions
- âœ… No mock data or placeholder responses

**Test File:** `tests/integration/capabilities/test_control_room_capability.py`

---

#### 20. Developer View
**Intents:** (Service endpoints for SDK/docs)

**Deep Dive Tests Required:**
- âœ… Developer endpoints return real SDK documentation
- âœ… Documentation is accurate and up-to-date
- âœ… API documentation reflects actual API
- âœ… No mock data or placeholder responses

**Test File:** `tests/integration/capabilities/test_developer_view_capability.py`

---

#### 21. Business User View
**Intents:** (Service endpoints for solution composition)

**Deep Dive Tests Required:**
- âœ… Business view endpoints return real solution data
- âœ… Solution composition works end-to-end
- âœ… No mock data or placeholder responses

**Test File:** `tests/integration/capabilities/test_business_user_view_capability.py`

---

## Test Execution Strategy

### Phase 1: Critical Capabilities (Days 1-2)
**Priority:** ðŸ”´ CRITICAL - Must work for executive demo

1. Workflow Creation
2. SOP Generation
3. Visual Generation
4. Solution Synthesis
5. Roadmap Generation

### Phase 2: Core Capabilities (Days 3-4)
**Priority:** ðŸŸ¡ HIGH - Core platform functionality

6. File Management
7. File Parsing
8. Data Quality Assessment
9. Interactive Analysis
10. Lineage Tracking

### Phase 3: Supporting Capabilities (Days 5-6)
**Priority:** ðŸŸ¢ MEDIUM - Important but not critical for demo

11. Data Ingestion
12. Bulk Operations
13. File Lifecycle
14. Semantic Interpretation
15. Guided Discovery
16. Coexistence Analysis
17. Coexistence Blueprint
18. POC Creation
19. Admin Dashboard (all views)

---

## Test Quality Criteria

### âœ… PASS Criteria (ALL must be true):
1. Execution completes successfully (status="completed")
2. Artifacts are created and stored
3. Artifacts contain meaningful data (not empty, not placeholder)
4. Artifacts are retrievable by artifact_id
5. Visuals are generated (if applicable) and are valid images
6. No errors or warnings in execution
7. No fallback mechanisms triggered
8. No mock data used

### âŒ FAIL Criteria (ANY of these = FAIL):
1. Execution fails or times out
2. Artifacts are not created
3. Artifacts are empty or contain placeholder data
4. Artifacts are not retrievable
5. Visuals are not generated when expected
6. Visuals are invalid or empty
7. Fallback mechanisms are triggered
8. Mock data is used
9. Hard-coded test data bypasses real functionality

---

## Anti-Patterns to AVOID

**ðŸš« NEVER DO THESE:**

1. **Mock Services**
   ```python
   # âŒ BAD
   @mock.patch('symphainy_platform.runtime.execution_lifecycle_manager.ExecutionLifecycleManager')
   
   # âœ… GOOD
   # Use real ExecutionLifecycleManager, test against real services
   ```

2. **Fallback Mechanisms**
   ```python
   # âŒ BAD
   try:
       artifact = await get_artifact(artifact_id)
   except:
       artifact = {"status": "created"}  # Fallback to placeholder
   
   # âœ… GOOD
   artifact = await get_artifact(artifact_id)
   assert artifact is not None  # Fail if not found, don't fake it
   ```

3. **Hard-Coded Test Data**
   ```python
   # âŒ BAD
   if test_mode:
       return {"workflow": "test_workflow"}  # Bypass real generation
   
   # âœ… GOOD
   # Always generate real workflow, validate it's real
   ```

4. **Placeholder Validation**
   ```python
   # âŒ BAD
   assert "artifact_id" in artifacts  # Just check key exists
   
   # âœ… GOOD
   artifact = artifacts["workflow_artifact"]
   assert artifact is not None
   assert "workflow_data" in artifact  # Check actual content
   assert len(artifact["workflow_data"]) > 0  # Not empty
   ```

---

## Test File Structure

```
tests/integration/capabilities/
â”œâ”€â”€ test_file_management_capability.py
â”œâ”€â”€ test_data_ingestion_capability.py
â”œâ”€â”€ test_file_parsing_capability.py
â”œâ”€â”€ test_bulk_operations_capability.py
â”œâ”€â”€ test_file_lifecycle_capability.py
â”œâ”€â”€ test_data_quality_capability.py
â”œâ”€â”€ test_semantic_interpretation_capability.py
â”œâ”€â”€ test_interactive_analysis_capability.py
â”œâ”€â”€ test_guided_discovery_capability.py
â”œâ”€â”€ test_lineage_tracking_capability.py
â”œâ”€â”€ test_workflow_creation_capability.py
â”œâ”€â”€ test_sop_generation_capability.py
â”œâ”€â”€ test_visual_generation_capability.py
â”œâ”€â”€ test_coexistence_analysis_capability.py
â”œâ”€â”€ test_coexistence_blueprint_capability.py
â”œâ”€â”€ test_solution_synthesis_capability.py
â”œâ”€â”€ test_roadmap_generation_capability.py
â”œâ”€â”€ test_poc_creation_capability.py
â”œâ”€â”€ test_control_room_capability.py
â”œâ”€â”€ test_developer_view_capability.py
â””â”€â”€ test_business_user_view_capability.py
```

---

## Next Steps

1. **Review this plan** - Ensure all capabilities are covered
2. **Create test files** - One per capability (or grouped by realm)
3. **Implement tests** - Follow mandatory test pattern
4. **Run tests** - Document all failures
5. **Fix issues** - NO FALLBACKS, fix root causes
6. **Re-test** - Ensure fixes work
7. **Track progress** - Update test matrix

---

**Last Updated:** January 18, 2026  
**Status:** ðŸ“‹ PLAN CREATED - Ready for implementation
